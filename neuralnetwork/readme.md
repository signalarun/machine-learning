1. [How to Configure the Number of Layers and Nodes in a Neural Network](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)
2. [How to evaluate the skill of deeplearning models](https://machinelearningmastery.com/evaluate-skill-deep-learning-models/)


# Multi-Class Neural Networks
  ## One Vs. All
    In this design each output node represent each class. It becomes inefficient as the number of classes rises.
  ## Softmax
    This design assigns decimal probabilities to each class in a multi-class problem, these probabilities also must add
    upto one.This constraint help training to converge more quickly than it otherwise would.Softmax assumes each
    datapoint is a member of exactly one class.
    
# Deep Neural Networks
  > "Deep learning is built around a hypothesis that a deep, hierarchical model can be exponentially more efficient at representing some functions than a shallow one."
  >                                                                                                            — How to Construct Deep Recurrent Neural Networks, 2013.
  > "RNNs are inherently deep in time, since their hidden state is a function of all previous hidden states. The question that inspired this paper was whether RNNs could also   
  > benefit from depth in space; that is from stacking multiple recurrent hidden layers on top of each other, just as feedforward layers are stacked in conventional deep
  > networks."
  >                                                                                                           — Speech Recognition With Deep Recurrent Neural Networks, 2013                                                                                                            
# [Decoding learning curves](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)

# Videos
 - [Batch size](https://www.youtube.com/watch?v=U4WB9p6ODjM)

# Libraries
 + [A distributed deeplearning library](https://singa.apache.org/)
